{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# как искать в xgb параметры - посмотреть в  google keeper (карпов)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подход Семина"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T09:45:42.735748Z",
     "start_time": "2021-09-19T09:45:42.726034Z"
    }
   },
   "outputs": [],
   "source": [
    "# модели\n",
    "\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, VotingClassifier, \\\n",
    "                            RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "import xgboost as xgb \n",
    "from xgboost.sklearn import XGBClassifier, XGBRegressor  # conda install py-xgboost\n",
    "import xgbfir\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "import xgbfir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T09:45:45.702930Z",
     "start_time": "2021-09-19T09:45:45.693262Z"
    }
   },
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, normalize, scale\n",
    "\n",
    "from sklearn.metrics import f1_score, recall_score, accuracy_score, roc_auc_score, precision_recall_fscore_support as score, \\\n",
    "                                    confusion_matrix, classification_report, mean_squared_error, mean_absolute_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T09:46:29.927196Z",
     "start_time": "2021-09-19T09:46:29.898694Z"
    }
   },
   "outputs": [],
   "source": [
    "# для выбора наилучшей модели\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials, space_eval\n",
    "# pip install future\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV,   \\\n",
    "                                                cross_val_score, cross_val_predict, learning_curve, \\\n",
    "                                                KFold, StratifiedKFold, TimeSeriesSplit\n",
    "# from sklearn import cross_validation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score, make_scorer\n",
    "kappa_scorer = make_scorer(cohen_kappa_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T09:46:50.626429Z",
     "start_time": "2021-09-19T09:46:50.620309Z"
    }
   },
   "outputs": [],
   "source": [
    "# снижение размерности\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T09:46:43.241695Z",
     "start_time": "2021-09-19T09:46:43.235775Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-19T09:47:01.504576Z",
     "start_time": "2021-09-19T09:47:01.498705Z"
    }
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотреть как предсказания завият от random state\n",
    "\n",
    "# ensembling prediction\n",
    "print('Starting the loop...')\n",
    "num_ensembles = 6\n",
    "y_test_pred = 0\n",
    "for i in tqdm(range(num_ensambles)): # tqdm - for visualization\n",
    "\tmodel = CatBoostClassifier(random_seed=i+42, **params ) # params = depth=6, iterations = 800, ...\n",
    "\tfit_model =  model.fit(train_data)\n",
    "\ty_test_pred += fit_model.predict_proba(test_data)[:,1]\n",
    "y_test_pred /= num_ensambles\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# график предсказний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "def boosting_fi(alg, X, n_feat=30):\n",
    "\n",
    "    feat_imp_df = pd.DataFrame({\"Feature\": X.columns, \"Score\": alg.feature_importances_})\n",
    "    feat_imp_df = feat_imp_df.sort_values(by='Score', ascending=False, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = (20, n_feat//2)\n",
    "    \n",
    "    ax = feat_imp_df[0:n_feat].plot('Feature', 'Score', kind='barh',color=list(plt.rcParams['axes.prop_cycle'])[0]['color'])\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(\"Feature Importance Ranking\", fontsize = 14)\n",
    "    plt.show()\n",
    "    return feat_imp_df\n",
    "\n",
    "# feat_imp_df = boosting_fi(alg, X_train_full, n_feat=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative feature importance\n",
    "def cum_fi(feat_imp_df, thr=0.95):\n",
    "\tfeat_imp_df['importance_normalized'] = feat_imp_df['Score'] / feat_imp_df['Score'].sum()\n",
    "\tfeat_imp_df['cumulative_importance'] = np.cumsum(feat_imp_df['importance_normalized'])\n",
    "\n",
    "\tcum_imp = list(feat_imp_df.cumulative_importance)\n",
    "\tfeature_list = list(feat_imp_df[\"Feature\"])\n",
    "\tx_values = list(range(feat_imp_df.shape[0]))\n",
    "\n",
    "\tfi_threshold = thr\n",
    "\n",
    "\ttop_feat = feat_imp_df[feat_imp_df.cumulative_importance < fi_threshold][\"Feature\"]\n",
    "\tprint('%d features needed for %d%% of cumulative importance' % (len(top_feat), fi_threshold*100))\n",
    "\n",
    "\tplt.figure(figsize = (16, 8))\n",
    "\tplt.rcParams['font.size'] = 13\n",
    "\tplt.plot(x_values, cum_imp, 'g-')\n",
    "\n",
    "\t# Draw line at thr% of importance retained\n",
    "\tplt.hlines(y = fi_threshold, xmin=0, xmax=len(feature_list), color = 'r', linestyles = 'dashed')\n",
    "\n",
    "\tplt.vlines(x = len(top_feat), ymin=0, ymax=1, color = 'black')\n",
    "\n",
    "\t# Format x ticks and labels\n",
    "\tplt.xticks(x_values, feature_list, rotation = 'vertical')\n",
    "\t# Axis labels and title\n",
    "\tplt.xlabel('Variable'); plt.ylabel('Cumulative Importance'); plt.title('Cumulative Importances');\n",
    "\n",
    "\treturn feat_imp_df, top_feat.values\n",
    "\n",
    "# feat_df, top_feat = cum_fi(feat_imp_df, thr=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal lr/tree number \n",
    "n_estimators = np.arange(100,550,50)\n",
    "learning_rate = np.geomspace(0.01, 1.0, 10)\n",
    "param_grid = dict(learning_rate = learning_rate, n_estimators=n_estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"recall\", n_jobs=-1, cv=kfold)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_[\"mean_test_score\"]\n",
    "stds = grid_result.cv_results_[\"std_test_score\"]\n",
    "params = grid_result.cv_results[\"params\"]\n",
    "for mean, stdev in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# делить модель по регионам "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "cv = StratifiedKFold(n_splits=K, random_state=42, shuffle=True)\n",
    "\n",
    "y_valid_pred = 0 * y_train_full\n",
    "y_test_pred = 0\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(cv.split(X_train_full, y_train_full)):\n",
    "    cb_init = cb.CatBoostClassifier(**init_params)\n",
    "    # Create data for this fold\n",
    "    y_train, y_valid = y_train_full.iloc[train_index], y_train_full.iloc[test_index]\n",
    "    X_train, X_valid = X_train_full.iloc[train_index,:], X_train_full.iloc[test_index,:]\n",
    "    print( \"\\nFold \", i+1)\n",
    "    \n",
    "    model_fit = cb_init.fit(X_train, y_train, \n",
    "                           cat_features=cat_feat_list,\n",
    "                           eval_set=Pool(X_valid, y_valid, cat_features=cat_feat_list),\n",
    "                           use_best_model=True,  \n",
    "                           plot=True,\n",
    "                           early_stopping_rounds=30,\n",
    "                )\n",
    "    \n",
    "    print( \" N trees = \", cb_init.tree_count_ )\n",
    "    \n",
    "#     cb_init.set_params(iterations=cb_init.tree_count_) # не используем, т.к. use_best_model=True\n",
    "    \n",
    "    # Generate validation predictions for this fold\n",
    "    pred = model_fit.predict(X_valid)\n",
    "    print( \" AUC on cv fold = \", np.round(roc_auc_score(y_valid, pred),4)) # повторяет график (пик)\n",
    "    y_valid_pred.iloc[test_index] = pred\n",
    "    \n",
    "    # Accumulate test set predictions\n",
    "    y_test_pred += model_fit.predict_proba(X_test)[:,1]\n",
    "    \n",
    "y_test_pred /= K  # Average test set predictions\n",
    "\n",
    "print( \"\\nAUC for full training set: \" , roc_auc_score(y_train_full, y_valid_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T16:33:46.774715Z",
     "start_time": "2021-09-24T16:33:46.761535Z"
    }
   },
   "outputs": [],
   "source": [
    "# class RmseMetric(object):\n",
    "#     def get_final_error(self, error, weight):\n",
    "#         return np.sqrt(error / (weight + 1e-38))\n",
    "\n",
    "#     def is_max_optimal(self):\n",
    "#         return False\n",
    "\n",
    "#     def evaluate(self, approxes, target, weight):\n",
    "#         assert len(approxes) == 1\n",
    "#         assert len(target) == len(approxes[0])\n",
    "\n",
    "#         approx = approxes[0]\n",
    "\n",
    "#         error_sum = 0.0\n",
    "#         weight_sum = 0.0\n",
    "\n",
    "#         for i in range(len(approx)):\n",
    "#             w = 1.0 if weight is None else weight[i]\n",
    "#             weight_sum += w\n",
    "#             error_sum += w * ((approx[i] - target[i])**2)\n",
    "\n",
    "#         return error_sum, weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-09-24T16:55:57.253209Z",
     "start_time": "2021-09-24T16:55:57.235508Z"
    }
   },
   "outputs": [],
   "source": [
    "class RmseMetric(object):\n",
    "    def get_final_error(self, error, weight):\n",
    "        return error / (weight + 1e-38)\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "\n",
    "        approx = approxes[0]\n",
    "\n",
    "        error_sum = 0.0\n",
    "        weight_sum = 0.0\n",
    "\n",
    "        for i in range(len(approx)):\n",
    "            \n",
    "            w = 1.0 if weight is None else weight[i]\n",
    "            \n",
    "            weight_sum += w\n",
    "            \n",
    "            dev = (target[i] - approx[i]) / target[i]\n",
    "            \n",
    "            const = 1.1\n",
    "            \n",
    "            if dev < -0.6:\n",
    "                hit = 9 * const\n",
    "            elif (dev >= -0.6) and (dev < -0.15):\n",
    "                hit = const * (1 + dev/0.15)**2\n",
    "            elif (dev >= -0.15) and (dev < 0.15):\n",
    "                hit = 0\n",
    "            elif (dev >= 0.15) and (dev < 0.6):\n",
    "                hit = (dev/0.15 - 1)**2\n",
    "            else:\n",
    "                hit = 9\n",
    "                \n",
    "            error_sum += w * hit\n",
    "\n",
    "        return error_sum, weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
